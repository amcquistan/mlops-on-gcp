{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b30e54",
   "metadata": {},
   "source": [
    "# Quotes Pipeline\n",
    "\n",
    "In this pipeline architecture a Cloud Scheduler Job is scheduled to run every couple of minutes which pushes a message to a Pub/Sub topic named quote-fetcher-topic. The quote-fetcher-topic Pub/Sub topic in turn invokes a Cloud Function named quote_fetcher which fetches random quotes from https://quotes.toscrape.com/random and, parses them from the webpage HTML and into a JSON datastructure then publishes the resulting JSON message into a second Pub/Sub topic named quotes. The quote Pub/Sub topic is comsumed by an Apache Beam Dataflow pipeline which parses the JSON based quote, calls the Natural Language ML API passing the quote text and receiving back sentiment scores which are added to the quote data structure. The Beam pipeline concludes by saving the sentiment enriched quotes to a BigQuery table named quotes in a quotesds dataset. \n",
    "\n",
    "<img src=\"./Quote-Sentiment-Pipeline.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf707c9",
   "metadata": {},
   "source": [
    "## Building the Quote Fetcher Cloud Function\n",
    "\n",
    "Steps are modified from GCP docs tutorial [Using Pub/Sub to trigger a Cloud Function](https://cloud.google.com/scheduler/docs/tut-pub-sub) along with the Quick Start example for [Functions Framework GitHub README](https://github.com/GoogleCloudPlatform/functions-framework-python)\n",
    "\n",
    "Quick View of Steps:\n",
    "\n",
    "1) Create Pub/Sub topic to write quotes to from Quote Fetcher Cloud Function\n",
    "\n",
    "2) Create Quote Fetcher Cloud Function \n",
    "\n",
    "3) Create Pub/Sub topic to trigger Quote Fetcher Cloud Function\n",
    "\n",
    "4) Create Cloud Scheduler job to invoke Pub/Sub topic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1649947",
   "metadata": {},
   "source": [
    "__Step 1:__ Create a pubsub topic for the Quote Fetcher cloud function to publish quotes to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681e7d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created topic [projects/qwiklabs-gcp-04-2ad6a04dc593/topics/quotes].\n"
     ]
    }
   ],
   "source": [
    "! gcloud pubsub topics create quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553abd5c",
   "metadata": {},
   "source": [
    "__Step 2:__ Create Quote Fetcher Cloud Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34555f93",
   "metadata": {},
   "source": [
    "First need a directory to hold the source code in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2afaec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quote_fetcher directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -d quote_fetcher ]\n",
    "then\n",
    "  echo \"creating quote_fetcher directory\"\n",
    "  mkdir quote_fetcher\n",
    "fi\n",
    "\n",
    "if [ ! -d pubsub_schd ]\n",
    "then\n",
    "  echo \"creating pubsub_schd directory\"\n",
    "  mkdir pubsub_schd\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709c84a9",
   "metadata": {},
   "source": [
    "Write requirements.txt for Quote Fetcher Cloud Function Python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf23428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./quote_fetcher/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./quote_fetcher/requirements.txt\n",
    "google-cloud-pubsub==2.7.0\n",
    "requests>=2.26.0,<2.27.0\n",
    "beautifulsoup4>=4.9.3,<4.10.0\n",
    "pydantic>=1.8.2,<1.9.0\n",
    "# google-cloud-language>=2.2.2,<2.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0465f",
   "metadata": {},
   "source": [
    "Write Quote Fetcher Cloud Function source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc06e571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./quote_fetcher/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./quote_fetcher/main.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import typing\n",
    "\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from google.cloud import pubsub_v1\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "TOPIC_ID = os.environ['TOPIC_ID']\n",
    "\n",
    "\n",
    "class Quote(BaseModel):\n",
    "    text : str\n",
    "    author : str\n",
    "    tags : typing.Sequence[str]\n",
    "    sentiment : typing.Optional[float]\n",
    "    magnitude : typing.Optional[float]\n",
    "        \n",
    "\n",
    "def fetch_quote(events, context):\n",
    "    quote_url = 'https://quotes.toscrape.com/random'\n",
    "\n",
    "    response = requests.get(quote_url)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    quote_el = soup.find('div', class_='quote')\n",
    "\n",
    "    quote = Quote(\n",
    "        text=quote_el.find('span', class_='text').get_text(),\n",
    "        author=quote_el.find('small', class_='author').get_text(),\n",
    "        tags=[el.get_text() for el in quote_el.find_all('a', class_='tag')]\n",
    "    )\n",
    "    \n",
    "    quote_data = quote.dict()\n",
    "    print(\"PROJECT_ID \" + PROJECT_ID)\n",
    "    print(\"TOPIC_ID \" + TOPIC_ID)\n",
    "    print(quote_data)\n",
    "    \n",
    "    publisher = pubsub_v1.PublisherClient()\n",
    "    topic_path = publisher.topic_path(PROJECT_ID, TOPIC_ID)\n",
    "    publisher.publish(topic_path, json.dumps(quote_data).encode('utf-8'))\n",
    "    \n",
    "    return quote_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cbb22d",
   "metadata": {},
   "source": [
    "__Step 3:__ Write a helper deployment shell script which also creates a Pub/Sub Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc33f951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./quote_fetcher/deploy-cloud-function.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./quote_fetcher/deploy-cloud-function.sh\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "if [ -d quote_fetcher ]\n",
    "then\n",
    "  cd quote_fetcher\n",
    "fi\n",
    "\n",
    "set -ex\n",
    "\n",
    "PROJECT_ID=$(gcloud config get-value project)\n",
    "TOPIC_ID=quotes\n",
    "\n",
    "gcloud functions deploy quote_fetcher \\\n",
    "  --set-env-vars PROJECT_ID=$PROJECT_ID,TOPIC_ID=$TOPIC_ID \\\n",
    "  --entry-point fetch_quote \\\n",
    "  --runtime python37 \\\n",
    "  --trigger-topic quote-fetcher-topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf254c4",
   "metadata": {},
   "source": [
    "Deploy the Quote Fetcher Cloud Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ede9be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "availableMemoryMb: 256\n",
      "buildId: b5d17b9e-fa1a-4d63-ae57-6e3ef5f41c9c\n",
      "buildName: projects/774131484409/locations/us-central1/builds/b5d17b9e-fa1a-4d63-ae57-6e3ef5f41c9c\n",
      "entryPoint: fetch_quote\n",
      "environmentVariables:\n",
      "  PROJECT_ID: qwiklabs-gcp-04-2ad6a04dc593\n",
      "  TOPIC_ID: quotes\n",
      "eventTrigger:\n",
      "  eventType: google.pubsub.topic.publish\n",
      "  failurePolicy: {}\n",
      "  resource: projects/qwiklabs-gcp-04-2ad6a04dc593/topics/quote-fetcher-topic\n",
      "  service: pubsub.googleapis.com\n",
      "ingressSettings: ALLOW_ALL\n",
      "labels:\n",
      "  deployment-tool: cli-gcloud\n",
      "name: projects/qwiklabs-gcp-04-2ad6a04dc593/locations/us-central1/functions/quote_fetcher\n",
      "runtime: python37\n",
      "serviceAccountEmail: qwiklabs-gcp-04-2ad6a04dc593@appspot.gserviceaccount.com\n",
      "sourceUploadUrl: https://storage.googleapis.com/gcf-upload-us-central1-0590737b-324c-4a57-b58b-fd974ee68e4f/54316c8d-fca6-4019-b329-11720ec78181.zip\n",
      "status: ACTIVE\n",
      "timeout: 60s\n",
      "updateTime: '2021-08-21T02:07:38.331Z'\n",
      "versionId: '1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+++ gcloud config get-value project\n",
      "++ PROJECT_ID=qwiklabs-gcp-04-2ad6a04dc593\n",
      "++ TOPIC_ID=quotes\n",
      "++ gcloud functions deploy quote_fetcher --set-env-vars PROJECT_ID=qwiklabs-gcp-04-2ad6a04dc593,TOPIC_ID=quotes --entry-point fetch_quote --runtime python37 --trigger-topic quote-fetcher-topic\n",
      "Deploying function (may take a while - up to 2 minutes)...\n",
      "..\n",
      "For Cloud Build Logs, visit: https://console.cloud.google.com/cloud-build/builds;region=us-central1/b5d17b9e-fa1a-4d63-ae57-6e3ef5f41c9c?project=774131484409\n",
      ".................................................done.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "chmod +x quote_fetcher/deploy-cloud-function.sh\n",
    "\n",
    "./quote_fetcher/deploy-cloud-function.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937dde89",
   "metadata": {},
   "source": [
    "Publish some data to the quote-fetcher-topic Pub/Sub topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71ec619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messageIds:\n",
      "- '2906104492847693'\n"
     ]
    }
   ],
   "source": [
    "! gcloud pubsub topics publish quote-fetcher-topic --message \"this is a test message\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb1c491",
   "metadata": {},
   "source": [
    "Check out the logs to make sure the Quote Fetcher Cloud Function is being Fired by Pub/Sub events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "886659e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEVEL  NAME           EXECUTION_ID  TIME_UTC                 LOG\n",
      "D      quote_fetcher  v2mpufvuid6d  2021-08-21 02:07:56.710  Function execution took 487 ms, finished with status: 'ok'\n",
      "I      quote_fetcher  v2mpufvuid6d  2021-08-21 02:07:56.485  {'text': '“You can never get a cup of tea large enough or a book long enough to suit me.”', 'author': 'C.S. Lewis', 'tags': ['books', 'inspirational', 'reading', 'tea'], 'sentiment': None, 'magnitude': None}\n",
      "I      quote_fetcher  v2mpufvuid6d  2021-08-21 02:07:56.485  TOPIC_ID quotes\n",
      "I      quote_fetcher  v2mpufvuid6d  2021-08-21 02:07:56.485  PROJECT_ID qwiklabs-gcp-04-2ad6a04dc593\n",
      "D      quote_fetcher  v2mpufvuid6d  2021-08-21 02:07:56.223  Function execution started\n",
      "D      quote_fetcher  v2mp1emgp6j7  2021-08-21 02:07:56.195  Function execution took 4026 ms, finished with status: 'ok'\n",
      "I      quote_fetcher  v2mp1emgp6j7  2021-08-21 02:07:55.559  {'text': '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', 'author': 'Albert Einstein', 'tags': ['inspirational', 'life', 'live', 'miracle', 'miracles'], 'sentiment': None, 'magnitude': None}\n",
      "I      quote_fetcher  v2mp1emgp6j7  2021-08-21 02:07:55.559  TOPIC_ID quotes\n",
      "I      quote_fetcher  v2mp1emgp6j7  2021-08-21 02:07:55.558  PROJECT_ID qwiklabs-gcp-04-2ad6a04dc593\n",
      "D      quote_fetcher  v2mp1emgp6j7  2021-08-21 02:07:52.172  Function execution started\n",
      "E      quote_fetcher  y4dnkr87mj95  2021-08-21 01:56:10.147  google.api_core.exceptions.NotFound: 404 Resource not found (resource=quotes).\n",
      "E      quote_fetcher  y4dnkr87mj95  2021-08-21 01:56:10.147      raise exceptions.from_grpc_error(exc) from exc\n"
     ]
    }
   ],
   "source": [
    "! gcloud functions logs read quote_fetcher --limit 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04f0c79",
   "metadata": {},
   "source": [
    "__Step 4:__ Create a Cloud Schedule Job to Push Messages to Pub/Sub which in turn Invokes the Cloud Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e1ffb",
   "metadata": {},
   "source": [
    "In cloud shell runt he following.\n",
    "\n",
    "```sh\n",
    "gcloud services enable cloudscheduler.googleapis.com\n",
    "\n",
    "export PROJECT_ID=$(gcloud config get-value project)\n",
    "gcloud app create --project $PROJECT_ID --region us-central\n",
    "\n",
    "gcloud scheduler jobs create pubsub quotefetcher \\\n",
    "  --schedule \"*/1 * * * *\" \\\n",
    "  --topic quote-fetcher-topic \\\n",
    "  --message-body \"fetch quote\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a5405",
   "metadata": {},
   "source": [
    "## Create a Dataflow Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c953cd5",
   "metadata": {},
   "source": [
    "Create a directory to hold Beam Pipeline code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bace605",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir quote_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeaea1c",
   "metadata": {},
   "source": [
    "Create a requriements.txt file for Beam Python library dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41d460a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./quote_pipeline/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./quote_pipeline/requirements.txt\n",
    "\n",
    "google-cloud-language==2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b33c75",
   "metadata": {},
   "source": [
    "Below is the pipeline code which consumes data from Pub/Sub quotes topic containing messages in JSON format as shown below.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"text\": \"Contents of a quote\",\n",
    "  \"author\": \"The Person Attributed with the Quote\",\n",
    "  \"tags\": ['A', 'list', 'of', 'tags', 'associated', 'with', 'quote'], \n",
    "  \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "755b63f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./quote_pipeline/pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./quote_pipeline/pipeline.py\n",
    "\n",
    "import argparse\n",
    "import typing\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io.gcp.internal.clients import bigquery\n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import StandardOptions, SetupOptions\n",
    "from apache_beam.runners import DataflowRunner\n",
    "\n",
    "import google.auth\n",
    "from google.cloud import language\n",
    "\n",
    "import time\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "class Quote(typing.NamedTuple):\n",
    "    text : str\n",
    "    author : str\n",
    "    tags : typing.Sequence[str]\n",
    "    sentiment : float\n",
    "    magnitude : float\n",
    "\n",
    "beam.coders.registry.register_coder(Quote, beam.coders.RowCoder)\n",
    "\n",
    "\n",
    "def analyze_quote(element):\n",
    "    row = json.loads(element.decode('utf-8'))\n",
    "    \n",
    "    client = language.LanguageServiceClient()\n",
    "    \n",
    "    doc = language.Document(content=row['text'],\n",
    "                            type_=language.Document.Type.PLAIN_TEXT)\n",
    "    \n",
    "    response = client.analyze_sentiment(document=doc)\n",
    "\n",
    "    row.update(\n",
    "      sentiment=response.document_sentiment.score,\n",
    "      magnitude=response.document_sentiment.magnitude\n",
    "    )\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "def main(args, beam_args):\n",
    "    options = PipelineOptions(beam_args,\n",
    "                              runner=args.runner,\n",
    "                              streaming=True,\n",
    "                              project=args.project,\n",
    "                              region=args.region,\n",
    "                              job_name='{}{}'.format('quotes-pipeline-', time.time_ns()),\n",
    "                              staging_location=args.staginglocation,\n",
    "                              temp_location=args.templocation,\n",
    "                              save_main_session=True)\n",
    "    \n",
    "    table_spec = bigquery.TableReference(projectId=args.project,\n",
    "                                         datasetId=args.bqdataset,\n",
    "                                         tableId=args.bqtable)\n",
    "    QUOTES_TABLE_SCHEMA = {\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"name\": \"text\",\n",
    "                \"type\": \"STRING\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"author\",\n",
    "                \"type\": \"STRING\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"tags\",\n",
    "                \"type\": \"STRING\",\n",
    "                \"mode\": \"REPEATED\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"sentiment\",\n",
    "                \"type\": \"FLOAT\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"sentiment\",\n",
    "                \"type\": \"FLOAT\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    with beam.Pipeline(options=options) as p:\n",
    "        (p  | \"ReadPubSub\" >> beam.io.ReadFromPubSub(args.pubsubtopic)\n",
    "            | \"AnalyzeQuote\" >> beam.Map(analyze_quote)\n",
    "            | \"SaveToBigQuery\" >> beam.io.WriteToBigQuery(\n",
    "                                          table_spec,\n",
    "                                          schema=QUOTES_TABLE_SCHEMA,\n",
    "                                          create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "                                          write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND))\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--runner', default='DataflowRunner')\n",
    "    parser.add_argument('--project')\n",
    "    parser.add_argument('--region')\n",
    "    parser.add_argument('--bqdataset')\n",
    "    parser.add_argument('--bqtable')\n",
    "    parser.add_argument('--staginglocation')\n",
    "    parser.add_argument('--templocation')\n",
    "    parser.add_argument('--pubsubtopic')\n",
    "    parser.add_argument('--requirements_file')\n",
    "    \n",
    "    args, beam_args = parser.parse_known_args()\n",
    "    \n",
    "    main(args, beam_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd619d1",
   "metadata": {},
   "source": [
    "Create Staging and Temp Dataflow Cloud Storage Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ce2e243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating gs://quotes-pipeline-qwiklabs-gcp-04-2ad6a04dc593/...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "export PROJECT_ID=$(gcloud config get-value project)\n",
    "PIPELINE_BUCKET=\"gs://quotes-pipeline-$PROJECT_ID\"\n",
    "gsutil mb -l US $PIPELINE_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3517071",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PROJECT_ID=$(gcloud config get-value project)\n",
    "PIPELINE_BUCKET=\"gs://quotes-pipeline-$PROJECT_ID\"\n",
    "python quote_pipeline/pipeline.py \\\n",
    "   --project $PROJECT_ID \\\n",
    "   --region us-central1 \\\n",
    "   --bqdataset quotesds \\\n",
    "   --bqtable quotes \\\n",
    "   --staginglocation $PIPELINE_BUCKET/staging \\\n",
    "   --templocation $PIPELINE_BUCKET/temp \\\n",
    "   --pubsubtopic projects/qwiklabs-gcp-04-2ad6a04dc593/topics/quotes \\\n",
    "   --requirements_file quote_pipeline/requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0591159",
   "metadata": {},
   "source": [
    "Error from last run "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25239ed",
   "metadata": {},
   "source": [
    "Error message from worker: generic::unknown: Traceback (most recent call last):\n",
    "  File \"apache_beam/runners/common.py\", line 1239, in apache_beam.runners.common.DoFnRunner.process\n",
    "  File \"apache_beam/runners/common.py\", line 588, in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
    "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/core.py\", line 1592, in <lambda>\n",
    "    wrapper = lambda x: [fn(x)]\n",
    "  File \"quote_pipeline/pipeline.py\", line 35, in analyze_quote\n",
    "AttributeError: module 'google.cloud.language' has no attribute 'Document'\n",
    "\n",
    "During handling of the above exception, another exception occurred:\n",
    "\n",
    "Traceback (most recent call last):\n",
    "  File \"/usr/local/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 289, in _execute\n",
    "    response = task()\n",
    "  File \"/usr/local/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 362, in <lambda>\n",
    "    lambda: self.create_worker().do_instruction(request), request)\n",
    "  File \"/usr/local/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 607, in do_instruction\n",
    "    getattr(request, request_type), request.instruction_id)\n",
    "  File \"/usr/local/lib/python3.7/site-packages/apache_beam/runners/worker/sdk_worker.py\", line 644, in process_bundle\n",
    "    bundle_processor.process_bundle(instruction_id))\n",
    "  File \"/usr/local/lib/python3.7/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 1000, in process_bundle\n",
    "    element.data)\n",
    "  File \"/usr/local/lib/python3.7/site-packages/apache_beam/runners/worker/bundle_processor.py\", line 228, in process_encoded\n",
    "    self.output(decoded_value)\n",
    "  File \"apache_beam/runners/worker/operations.py\", line 357, in apache_beam.runners.worker.operations.Operation.output\n",
    "  File \"apache_beam/runners/worker/operations.py\", line 359, in apache_beam.runners.worker.operations.Operation.output\n",
    "  File \"apache_beam/runners/worker/operations.py\", line 221, in apache_beam.runners.worker.operations.SingletonConsumerSet.receive\n",
    "  File \"apache_beam/runners/worker/operations.py\", line 718, in apache_beam.runners.worker.operations.DoOperation.process\n",
    "  File \"apache_beam/runners/worker/operations.py\", line 719, in apache_beam.runners.worker.operations.DoOperation.process\n",
    "  File \"apache_beam/runners/common.py\", line 1241, in apache_beam.runners.common.DoFnRunner.process\n",
    "  File \"apache_beam/runners/common.py\", line 1321, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
    "  File \"/usr/local/lib/python3.7/site-packages/future/utils/__init__.py\", line 446, in raise_with_traceback\n",
    "    raise exc.with_traceback(traceback)\n",
    "  File \"apache_beam/runners/common.py\", line 1239, in apache_beam.runners.common.DoFnRunner.process\n",
    "  File \"apache_beam/runners/common.py\", line 588, in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
    "  File \"/opt/conda/lib/python3.7/site-packages/apache_beam/transforms/core.py\", line 1592, in <lambda>\n",
    "    wrapper = lambda x: [fn(x)]\n",
    "  File \"quote_pipeline/pipeline.py\", line 35, in analyze_quote\n",
    "AttributeError: module 'google.cloud.language' has no attribute 'Document' [while running 'AnalyzeQuote-ptransform-42']\n",
    "\n",
    "passed through:\n",
    "==>\n",
    "    dist_proc/dax/workflow/worker/fnapi_service_impl.cc:644\n",
    "Hide log summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b04e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
